{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¬ MovieRec AI - FAANG-Grade Recommender Training\n",
                "\n",
                "Train a Two-Tower recommendation model on MovieLens with Free GPU!\n",
                "\n",
                "**Output Files (download after training):**\n",
                "- `item_embeddings.npy` - Upload to Hugging Face\n",
                "- `user_embeddings.npy` - Upload to Hugging Face  \n",
                "- `production.index` - FAISS index\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Kaggle has most packages pre-installed!\n",
                "# Just verify and install any missing ones\n",
                "!pip install -q faiss-cpu tqdm scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from tqdm.auto import tqdm\n",
                "import faiss\n",
                "\n",
                "# Check GPU\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load MovieLens Data\n",
                "\n",
                "**IMPORTANT**: Add the dataset first!\n",
                "1. Click '+Add Data' on the right sidebar\n",
                "2. Search 'movielens'\n",
                "3. Add 'MovieLens 20M Dataset' or 'The Movies Dataset'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find the data path (different datasets have different structures)\n",
                "import os\n",
                "\n",
                "possible_paths = [\n",
                "    '/kaggle/input/movielens-20m-dataset/',\n",
                "    '/kaggle/input/the-movies-dataset/',\n",
                "    '/kaggle/input/movielens-latest-full/',\n",
                "    '/kaggle/input/'\n",
                "]\n",
                "\n",
                "DATA_PATH = None\n",
                "for path in possible_paths:\n",
                "    if os.path.exists(path):\n",
                "        files = os.listdir(path)\n",
                "        print(f\"{path}: {files[:5]}\")\n",
                "        if any('rating' in f.lower() for f in files):\n",
                "            DATA_PATH = path\n",
                "            break\n",
                "\n",
                "if DATA_PATH is None:\n",
                "    print(\"âš ï¸ No data found! Please add a MovieLens dataset.\")\n",
                "else:\n",
                "    print(f\"\\nâœ… Using: {DATA_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load ratings\n",
                "rating_files = [f for f in os.listdir(DATA_PATH) if 'rating' in f.lower() and f.endswith('.csv')]\n",
                "print(f\"Found rating files: {rating_files}\")\n",
                "\n",
                "ratings = pd.read_csv(os.path.join(DATA_PATH, rating_files[0]))\n",
                "print(f\"Loaded {len(ratings):,} ratings\")\n",
                "print(ratings.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample for faster training (reduce if you have time)\n",
                "SAMPLE_SIZE = 2_000_000  # 2M ratings - trains in ~10 min on GPU\n",
                "\n",
                "if len(ratings) > SAMPLE_SIZE:\n",
                "    ratings = ratings.sample(n=SAMPLE_SIZE, random_state=42)\n",
                "    print(f\"Sampled to {len(ratings):,} ratings\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocess Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode user and item IDs to contiguous integers\n",
                "user_encoder = LabelEncoder()\n",
                "item_encoder = LabelEncoder()\n",
                "\n",
                "ratings['user_idx'] = user_encoder.fit_transform(ratings['userId'])\n",
                "ratings['item_idx'] = item_encoder.fit_transform(ratings['movieId'])\n",
                "\n",
                "num_users = ratings['user_idx'].nunique()\n",
                "num_items = ratings['item_idx'].nunique()\n",
                "\n",
                "print(f\"Users: {num_users:,}\")\n",
                "print(f\"Items: {num_items:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/val split (80/20)\n",
                "train_size = int(0.8 * len(ratings))\n",
                "train_data = ratings.iloc[:train_size]\n",
                "val_data = ratings.iloc[train_size:]\n",
                "\n",
                "print(f\"Train: {len(train_data):,}, Val: {len(val_data):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Define Two-Tower Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TwoTowerModel(nn.Module):\n",
                "    \"\"\"Two-Tower (Dual Encoder) model for recommendations.\"\"\"\n",
                "    \n",
                "    def __init__(self, num_users, num_items, embedding_dim=128, output_dim=64):\n",
                "        super().__init__()\n",
                "        \n",
                "        # User tower\n",
                "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
                "        self.user_mlp = nn.Sequential(\n",
                "            nn.Linear(embedding_dim, 256),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.1),\n",
                "            nn.Linear(256, 128),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(128, output_dim)\n",
                "        )\n",
                "        \n",
                "        # Item tower\n",
                "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
                "        self.item_mlp = nn.Sequential(\n",
                "            nn.Linear(embedding_dim, 256),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.1),\n",
                "            nn.Linear(256, 128),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(128, output_dim)\n",
                "        )\n",
                "        \n",
                "        self._init_weights()\n",
                "        \n",
                "    def _init_weights(self):\n",
                "        for module in self.modules():\n",
                "            if isinstance(module, nn.Embedding):\n",
                "                nn.init.normal_(module.weight, std=0.01)\n",
                "            elif isinstance(module, nn.Linear):\n",
                "                nn.init.xavier_uniform_(module.weight)\n",
                "                if module.bias is not None:\n",
                "                    nn.init.zeros_(module.bias)\n",
                "    \n",
                "    def get_user_embeddings(self, user_ids):\n",
                "        x = self.user_embedding(user_ids)\n",
                "        x = self.user_mlp(x)\n",
                "        return F.normalize(x, p=2, dim=-1)\n",
                "    \n",
                "    def get_item_embeddings(self, item_ids):\n",
                "        x = self.item_embedding(item_ids)\n",
                "        x = self.item_mlp(x)\n",
                "        return F.normalize(x, p=2, dim=-1)\n",
                "    \n",
                "    def forward(self, user_ids, item_ids):\n",
                "        user_emb = self.get_user_embeddings(user_ids)\n",
                "        item_emb = self.get_item_embeddings(item_ids)\n",
                "        return user_emb, item_emb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Dataset & DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class InteractionDataset(Dataset):\n",
                "    def __init__(self, df):\n",
                "        self.users = torch.LongTensor(df['user_idx'].values)\n",
                "        self.items = torch.LongTensor(df['item_idx'].values)\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.users)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return self.users[idx], self.items[idx]\n",
                "\n",
                "train_dataset = InteractionDataset(train_data)\n",
                "val_dataset = InteractionDataset(val_data)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True, num_workers=2)\n",
                "val_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False, num_workers=2)\n",
                "\n",
                "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Training with InfoNCE Loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def info_nce_loss(user_emb, item_emb, temperature=0.07):\n",
                "    \"\"\"InfoNCE loss with in-batch negatives.\"\"\"\n",
                "    logits = torch.mm(user_emb, item_emb.t()) / temperature\n",
                "    labels = torch.arange(logits.size(0), device=logits.device)\n",
                "    return F.cross_entropy(logits, labels)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize model\n",
                "model = TwoTowerModel(num_users, num_items).to(device)\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
                "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
                "\n",
                "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training loop\n",
                "NUM_EPOCHS = 10\n",
                "best_loss = float('inf')\n",
                "\n",
                "for epoch in range(NUM_EPOCHS):\n",
                "    model.train()\n",
                "    train_loss = 0\n",
                "    \n",
                "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
                "    for users, items in pbar:\n",
                "        users, items = users.to(device), items.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        user_emb, item_emb = model(users, items)\n",
                "        loss = info_nce_loss(user_emb, item_emb)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        train_loss += loss.item()\n",
                "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
                "    \n",
                "    train_loss /= len(train_loader)\n",
                "    \n",
                "    # Validation\n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    with torch.no_grad():\n",
                "        for users, items in val_loader:\n",
                "            users, items = users.to(device), items.to(device)\n",
                "            user_emb, item_emb = model(users, items)\n",
                "            val_loss += info_nce_loss(user_emb, item_emb).item()\n",
                "    val_loss /= len(val_loader)\n",
                "    \n",
                "    scheduler.step()\n",
                "    \n",
                "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
                "    \n",
                "    if val_loss < best_loss:\n",
                "        best_loss = val_loss\n",
                "        torch.save(model.state_dict(), 'best_model.pt')\n",
                "        print(\"  â†’ Saved best model!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Export Embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.load_state_dict(torch.load('best_model.pt'))\n",
                "model.eval()\n",
                "print(\"Generating embeddings...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate item embeddings\n",
                "item_embeddings = []\n",
                "batch_size = 1024\n",
                "\n",
                "with torch.no_grad():\n",
                "    for i in tqdm(range(0, num_items, batch_size), desc=\"Item embeddings\"):\n",
                "        batch_ids = torch.arange(i, min(i + batch_size, num_items), device=device)\n",
                "        emb = model.get_item_embeddings(batch_ids)\n",
                "        item_embeddings.append(emb.cpu().numpy())\n",
                "\n",
                "item_embeddings = np.vstack(item_embeddings).astype(np.float32)\n",
                "print(f\"Item embeddings shape: {item_embeddings.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate user embeddings\n",
                "user_embeddings = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for i in tqdm(range(0, num_users, batch_size), desc=\"User embeddings\"):\n",
                "        batch_ids = torch.arange(i, min(i + batch_size, num_users), device=device)\n",
                "        emb = model.get_user_embeddings(batch_ids)\n",
                "        user_embeddings.append(emb.cpu().numpy())\n",
                "\n",
                "user_embeddings = np.vstack(user_embeddings).astype(np.float32)\n",
                "print(f\"User embeddings shape: {user_embeddings.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save embeddings\n",
                "np.save('item_embeddings.npy', item_embeddings)\n",
                "np.save('user_embeddings.npy', user_embeddings)\n",
                "\n",
                "metadata = {'num_users': num_users, 'num_items': num_items, 'embedding_dim': 64}\n",
                "with open('metadata.json', 'w') as f:\n",
                "    json.dump(metadata, f)\n",
                "\n",
                "print(\"âœ… Saved embeddings and metadata!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Build FAISS Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Normalize for cosine similarity\n",
                "item_emb_normalized = item_embeddings.copy()\n",
                "faiss.normalize_L2(item_emb_normalized)\n",
                "\n",
                "# Build simple flat index (CPU, works everywhere)\n",
                "dim = item_embeddings.shape[1]\n",
                "index = faiss.IndexFlatIP(dim)  # Inner product = cosine sim for normalized vectors\n",
                "index.add(item_emb_normalized)\n",
                "\n",
                "print(f\"âœ… Index contains {index.ntotal} vectors\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save FAISS index\n",
                "faiss.write_index(index, 'production.index')\n",
                "print(\"âœ… Saved FAISS index!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Test Recommendations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test: Get recommendations for user 0\n",
                "user_id = 0\n",
                "user_emb = user_embeddings[user_id:user_id+1].copy()\n",
                "faiss.normalize_L2(user_emb)\n",
                "\n",
                "distances, indices = index.search(user_emb, k=10)\n",
                "\n",
                "print(f\"Top 10 recommendations for user {user_id}:\")\n",
                "for i, (idx, score) in enumerate(zip(indices[0], distances[0])):\n",
                "    print(f\"  {i+1}. Item {idx} (score: {score:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Download Files\n",
                "\n",
                "Download these files and upload to Hugging Face Spaces:\n",
                "\n",
                "1. `item_embeddings.npy`\n",
                "2. `user_embeddings.npy`\n",
                "3. `metadata.json`\n",
                "4. `production.index`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List output files\n",
                "for f in ['item_embeddings.npy', 'user_embeddings.npy', 'metadata.json', 'production.index', 'best_model.pt']:\n",
                "    if os.path.exists(f):\n",
                "        size_mb = os.path.getsize(f) / (1024 * 1024)\n",
                "        print(f\"âœ… {f}: {size_mb:.2f} MB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\"\"\n",
                "ðŸŽ‰ Training Complete!\n",
                "\n",
                "Next Steps:\n",
                "1. Click 'Output' tab in Kaggle sidebar (right side)\n",
                "2. Download these files:\n",
                "   - item_embeddings.npy\n",
                "   - user_embeddings.npy\n",
                "   - metadata.json\n",
                "   - production.index\n",
                "3. Upload to Hugging Face Spaces\n",
                "\"\"\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}